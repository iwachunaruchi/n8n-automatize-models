#!/usr/bin/env python3
"""
Script para crear datos sintÃ©ticos de entrenamiento
Genera parejas clean/degraded a partir de imÃ¡genes limpias
"""

import os
import cv2
import numpy as np
import random
from PIL import Image, ImageFilter, ImageEnhance
import argparse

def add_noise(image, noise_level=0.1):
    """Agregar ruido gaussiano"""
    h, w, c = image.shape
    noise = np.random.normal(0, noise_level * 255, (h, w, c))
    noisy = image + noise
    return np.clip(noisy, 0, 255).astype(np.uint8)

def add_blur(image, blur_strength=1.5):
    """Agregar desenfoque"""
    return cv2.GaussianBlur(image, (5, 5), blur_strength)

def add_compression_artifacts(image, quality=30):
    """Simular artefactos de compresiÃ³n JPEG"""
    # Convertir a PIL
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Simular compresiÃ³n JPEG de baja calidad
    import io
    buffer = io.BytesIO()
    pil_image.save(buffer, format='JPEG', quality=quality)
    buffer.seek(0)
    compressed = Image.open(buffer)
    
    # Volver a OpenCV
    return cv2.cvtColor(np.array(compressed), cv2.COLOR_RGB2BGR)

def adjust_brightness_contrast(image, brightness=0.8, contrast=0.9):
    """Ajustar brillo y contraste"""
    # Convertir a PIL
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Ajustar brillo
    enhancer = ImageEnhance.Brightness(pil_image)
    pil_image = enhancer.enhance(brightness)
    
    # Ajustar contraste
    enhancer = ImageEnhance.Contrast(pil_image)
    pil_image = enhancer.enhance(contrast)
    
    # Volver a OpenCV
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

def add_shadow_stains(image):
    """Agregar manchas y sombras simuladas"""
    h, w = image.shape[:2]
    
    # Crear mÃ¡scara de manchas
    mask = np.ones((h, w), dtype=np.uint8) * 255
    
    # Agregar algunas manchas circulares
    for _ in range(random.randint(2, 5)):
        center = (random.randint(0, w), random.randint(0, h))
        radius = random.randint(20, 60)
        intensity = random.randint(180, 220)
        cv2.circle(mask, center, radius, intensity, -1)
    
    # Suavizar la mÃ¡scara
    mask = cv2.GaussianBlur(mask, (15, 15), 0)
    mask = mask.astype(np.float32) / 255.0
    
    # Aplicar la mÃ¡scara
    result = image.copy().astype(np.float32)
    for c in range(3):
        result[:, :, c] *= mask
    
    return np.clip(result, 0, 255).astype(np.uint8)

def degrade_document(image, degradation_level='medium'):
    """
    Aplicar mÃºltiples degradaciones a una imagen de documento
    """
    result = image.copy()
    
    if degradation_level == 'light':
        # DegradaciÃ³n ligera
        result = add_noise(result, 0.05)
        result = add_blur(result, 0.8)
        result = adjust_brightness_contrast(result, 0.95, 0.95)
        
    elif degradation_level == 'medium':
        # DegradaciÃ³n media
        result = add_noise(result, 0.1)
        result = add_blur(result, 1.2)
        result = add_compression_artifacts(result, 40)
        result = adjust_brightness_contrast(result, 0.85, 0.85)
        
        if random.random() > 0.5:
            result = add_shadow_stains(result)
            
    elif degradation_level == 'heavy':
        # DegradaciÃ³n fuerte
        result = add_noise(result, 0.15)
        result = add_blur(result, 2.0)
        result = add_compression_artifacts(result, 25)
        result = adjust_brightness_contrast(result, 0.7, 0.7)
        result = add_shadow_stains(result)
    
    return result

def add_geometric_distortions(image):
    """Agregar distorsiones geomÃ©tricas sutiles"""
    h, w = image.shape[:2]
    
    try:
        # Crear puntos de control para transformaciÃ³n perspectiva
        pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])
        
        # PequeÃ±as distorsiones aleatorias
        offset = min(w, h) * 0.01  # Reducir a 1% para evitar problemas
        pts2 = pts1.copy()
        
        # Aplicar offsets pequeÃ±os y seguros
        for i in range(4):
            pts2[i][0] += random.uniform(-offset, offset)
            pts2[i][1] += random.uniform(-offset, offset)
        
        # Asegurar que los puntos sean vÃ¡lidos
        pts2[0] = np.maximum(pts2[0], [0, 0])  # Top-left
        pts2[1] = np.minimum(pts2[1], [w, 0])  # Top-right
        pts2[2] = np.maximum(pts2[2], [0, h])  # Bottom-left
        pts2[3] = np.minimum(pts2[3], [w, h])  # Bottom-right
        
        # Aplicar transformaciÃ³n perspectiva
        M = cv2.getPerspectiveTransform(pts1, pts2)
        result = cv2.warpPerspective(image, M, (w, h))
        
        return result
    except:
        # Si hay error, retornar imagen original
        return image

def add_color_variations(image):
    """Agregar variaciones de color realistas"""
    # ConversiÃ³n a HSV para manipular color
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)
    
    # Variaciones en hue (tinte)
    hue_shift = random.uniform(-10, 10)
    hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift) % 180
    
    # Variaciones en saturaciÃ³n
    sat_factor = random.uniform(0.8, 1.2)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * sat_factor, 0, 255)
    
    # Variaciones en valor (brillo)
    val_factor = random.uniform(0.85, 1.15)
    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * val_factor, 0, 255)
    
    # Volver a BGR
    result = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
    return result

def add_texture_noise(image):
    """Agregar ruido de textura tipo papel"""
    h, w, c = image.shape
    
    # Crear textura de papel
    paper_texture = np.random.normal(1.0, 0.05, (h, w))
    paper_texture = cv2.GaussianBlur(paper_texture, (3, 3), 0)
    
    # Aplicar textura
    result = image.astype(np.float32)
    for channel in range(c):
        result[:, :, channel] *= paper_texture
    
    return np.clip(result, 0, 255).astype(np.uint8)

def add_random_patches(image):
    """Agregar parches aleatorios de degradaciÃ³n"""
    result = image.copy()
    h, w = image.shape[:2]
    
    # NÃºmero aleatorio de parches
    num_patches = random.randint(0, 3)
    
    for _ in range(num_patches):
        # TamaÃ±o del parche
        patch_size = random.randint(20, 80)
        
        # PosiciÃ³n aleatoria
        x = random.randint(0, max(0, w - patch_size))
        y = random.randint(0, max(0, h - patch_size))
        
        # Tipo de degradaciÃ³n del parche
        patch_type = random.choice(['blur', 'darken', 'noise'])
        
        patch = result[y:y+patch_size, x:x+patch_size].copy()
        
        if patch_type == 'blur':
            patch = cv2.GaussianBlur(patch, (7, 7), 2.0)
        elif patch_type == 'darken':
            patch = (patch * 0.6).astype(np.uint8)
        elif patch_type == 'noise':
            noise = np.random.normal(0, 30, patch.shape)
            patch = np.clip(patch + noise, 0, 255).astype(np.uint8)
        
        result[y:y+patch_size, x:x+patch_size] = patch
    
    return result

def degrade_document_advanced(image, degradation_params=None):
    """
    Aplicar degradaciones avanzadas con parÃ¡metros personalizables
    """
    if degradation_params is None:
        # ParÃ¡metros aleatorios
        degradation_params = {
            'noise_level': random.uniform(0.02, 0.15),
            'blur_strength': random.uniform(0.5, 2.5),
            'jpeg_quality': random.randint(20, 60),
            'brightness': random.uniform(0.7, 1.1),
            'contrast': random.uniform(0.7, 1.1),
            'add_shadows': random.random() > 0.6,
            'add_geometric': random.random() > 0.7,
            'add_color_shift': random.random() > 0.5,
            'add_texture': random.random() > 0.6,
            'add_patches': random.random() > 0.8
        }
    
    result = image.copy()
    
    # Aplicar degradaciones en orden aleatorio para mayor variedad
    degradations = []
    
    if degradation_params.get('add_geometric', False):
        degradations.append(('geometric', add_geometric_distortions))
    
    if degradation_params.get('add_color_shift', False):
        degradations.append(('color', add_color_variations))
    
    degradations.extend([
        ('noise', lambda img: add_noise(img, degradation_params['noise_level'])),
        ('blur', lambda img: add_blur(img, degradation_params['blur_strength'])),
        ('compression', lambda img: add_compression_artifacts(img, degradation_params['jpeg_quality'])),
        ('brightness', lambda img: adjust_brightness_contrast(img, 
                                                            degradation_params['brightness'], 
                                                            degradation_params['contrast']))
    ])
    
    if degradation_params.get('add_shadows', False):
        degradations.append(('shadows', add_shadow_stains))
    
    if degradation_params.get('add_texture', False):
        degradations.append(('texture', add_texture_noise))
    
    if degradation_params.get('add_patches', False):
        degradations.append(('patches', add_random_patches))
    
    # Mezclar orden de aplicaciÃ³n
    random.shuffle(degradations)
    
    # Aplicar degradaciones
    for name, func in degradations:
        try:
            result = func(result)
        except Exception as e:
            print(f"âš ï¸ Error en degradaciÃ³n {name}: {e}")
            continue
    
    return result

def create_massive_training_pairs(target_count=500):
    """Crear dataset masivo de 500+ pares de entrenamiento"""
    
    print("ğŸ­ CREANDO DATASET MASIVO DE ENTRENAMIENTO")
    print("=" * 60)
    print(f"ğŸ¯ Meta: {target_count} imÃ¡genes degradadas")
    
    # Directorios
    clean_dir = "data/train/clean"
    degraded_dir = "data/train/degraded"
    
    # Crear directorios si no existen
    os.makedirs(degraded_dir, exist_ok=True)
    
    # Obtener imÃ¡genes limpias
    if not os.path.exists(clean_dir):
        print(f"âŒ Error: No existe {clean_dir}")
        return
    
    clean_files = [f for f in os.listdir(clean_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    if not clean_files:
        print(f"âŒ Error: No hay imÃ¡genes en {clean_dir}")
        return
    
    print(f"ğŸ“ Encontradas {len(clean_files)} imÃ¡genes limpias base")
    
    # Cargar todas las imÃ¡genes limpias
    clean_images = {}
    for clean_file in clean_files:
        clean_path = os.path.join(clean_dir, clean_file)
        image = cv2.imread(clean_path)
        if image is not None:
            clean_images[clean_file] = image
            print(f"âœ… Cargada: {clean_file} ({image.shape[1]}x{image.shape[0]})")
    
    if not clean_images:
        print("âŒ No se pudieron cargar imÃ¡genes")
        return
    
    print(f"\nğŸ² Generando {target_count} variaciones degradadas...")
    
    # Calcular cuÃ¡ntas variaciones por imagen base
    variations_per_image = target_count // len(clean_images)
    extra_variations = target_count % len(clean_images)
    
    print(f"ï¿½ {variations_per_image} variaciones por imagen base")
    print(f"ğŸ“Š {extra_variations} variaciones extra en primeras imÃ¡genes")
    
    total_created = 0
    progress_step = max(1, target_count // 20)  # Mostrar progreso cada 5%
    
    for idx, (clean_file, clean_image) in enumerate(clean_images.items()):
        base_name = os.path.splitext(clean_file)[0]
        
        # Calcular variaciones para esta imagen
        num_variations = variations_per_image
        if idx < extra_variations:
            num_variations += 1
        
        print(f"\nğŸ“ Procesando {clean_file}: {num_variations} variaciones")
        
        for var_idx in range(num_variations):
            try:
                # Crear degradaciÃ³n Ãºnica
                degraded = degrade_document_advanced(clean_image)
                
                # Nombre Ãºnico
                degraded_filename = f"{base_name}_synthetic_{var_idx+1:03d}.png"
                degraded_path = os.path.join(degraded_dir, degraded_filename)
                
                # Guardar
                cv2.imwrite(degraded_path, degraded)
                total_created += 1
                
                # Mostrar progreso
                if total_created % progress_step == 0:
                    progress = (total_created / target_count) * 100
                    print(f"   ğŸ“ˆ Progreso: {total_created}/{target_count} ({progress:.1f}%)")
                
            except Exception as e:
                print(f"âŒ Error creando variaciÃ³n {var_idx+1}: {e}")
                continue
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ DATASET MASIVO COMPLETADO!")
    print(f"âœ… Creadas {total_created} imÃ¡genes degradadas sintÃ©ticas")
    print(f"ğŸ“ Guardadas en: {degraded_dir}")
    print(f"ğŸ“Š Ratio de expansiÃ³n: {total_created/len(clean_images):.1f}x")
    
    # EstadÃ­sticas del dataset
    print(f"\nğŸ“ˆ ESTADÃSTICAS DEL DATASET:")
    print(f"   ğŸ–¼ï¸ ImÃ¡genes limpias: {len(clean_images)}")
    print(f"   ğŸ”„ ImÃ¡genes degradadas: {total_created}")
    print(f"   ğŸ“Š Total de pares: {total_created}")
    print(f"   ğŸ’¾ Espacio estimado: ~{total_created * 0.5:.1f} MB")
    
    return total_created

def create_training_pairs():
    """FunciÃ³n original mantenida para compatibilidad"""
    return create_massive_training_pairs(target_count=500)
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ RESUMEN:")
    print(f"âœ… Creadas {total_created} imÃ¡genes degradadas sintÃ©ticas")
    print(f"ğŸ“ Guardadas en: {degraded_dir}")
    print("\nğŸš€ Â¡Ahora puedes entrenar tu modelo!")
    print("   Ejecuta: python src/train.py --config config/train_config.yaml")

def expand_clean_dataset():
    """Expandir el dataset limpio usando las imÃ¡genes de validaciÃ³n"""
    
    print("\nğŸ”„ EXPANDIENDO DATASET LIMPIO")
    print("-" * 40)
    
    val_clean_dir = "data/val/clean" 
    train_clean_dir = "data/train/clean"
    
    if not os.path.exists(val_clean_dir):
        print("âŒ No existe directorio val/clean")
        return
    
    val_files = [f for f in os.listdir(val_clean_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    copied = 0
    for file in val_files:
        src = os.path.join(val_clean_dir, file)
        dst = os.path.join(train_clean_dir, f"val_{file}")
        
        # Verificar que no existe ya
        if not os.path.exists(dst):
            img = cv2.imread(src)
            if img is not None:
                cv2.imwrite(dst, img)
                print(f"   âœ… Copiada: {file} â†’ val_{file}")
                copied += 1
    
    print(f"ğŸ“Š Copiadas {copied} imÃ¡genes adicionales al dataset de entrenamiento")

if __name__ == "__main__":
    print("ğŸ¯ GENERADOR DE DATASET MASIVO")
    print("=" * 50)
    
    # Primero expandir dataset si es necesario
    try:
        expand_clean_dataset()
    except Exception as e:
        print(f"âš ï¸ Error expandiendo dataset: {e}")
    
    # Crear dataset masivo de 500 imÃ¡genes
    try:
        total_created = create_massive_training_pairs(target_count=500)
        
        if total_created > 0:
            print(f"\nğŸ‰ Â¡Ã‰XITO! Dataset expandido a {total_created} imÃ¡genes")
            print("ğŸš€ Â¡Listo para transfer learning gradual!")
        else:
            print("\nâŒ No se crearon imÃ¡genes")
            
    except Exception as e:
        print(f"\nğŸ’¥ Error: {e}")
        import traceback
        traceback.print_exc()
