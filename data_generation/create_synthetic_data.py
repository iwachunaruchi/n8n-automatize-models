#!/usr/bin/env python3
"""
GENERACI√ìN MASIVA DE DATOS SINT√âTICOS
Versi√≥n optimizada para el Transfer Learning Gradual
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance
import random
import io
from tqdm import tqdm

def add_geometric_distortions(image):
    """Agregar distorsiones geom√©tricas leves"""
    h, w = image.shape[:2]
    
    # Transformaci√≥n de perspectiva sutil
    pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])
    
    # Variaciones peque√±as para simular documentos escaneados
    offset = min(w, h) * 0.02  # 2% de distorsi√≥n m√°xima
    
    pts2 = np.float32([
        [random.uniform(-offset, offset), random.uniform(-offset, offset)],
        [w + random.uniform(-offset, offset), random.uniform(-offset, offset)], 
        [random.uniform(-offset, offset), h + random.uniform(-offset, offset)],
        [w + random.uniform(-offset, offset), h + random.uniform(-offset, offset)]
    ])
    
    matrix = cv2.getPerspectiveTransform(pts1, pts2)
    distorted = cv2.warpPerspective(image, matrix, (w, h), 
                                   borderMode=cv2.BORDER_REFLECT_101)
    
    return distorted

def add_color_variations(image):
    """Agregar variaciones de color sutiles"""
    # Convertir a PIL para mejor control de color
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Ajustes sutiles de brillo y contraste
    brightness = random.uniform(0.85, 1.15)
    contrast = random.uniform(0.9, 1.1)
    saturation = random.uniform(0.95, 1.05)
    
    # Aplicar ajustes
    enhancer = ImageEnhance.Brightness(pil_image)
    pil_image = enhancer.enhance(brightness)
    
    enhancer = ImageEnhance.Contrast(pil_image)
    pil_image = enhancer.enhance(contrast)
    
    enhancer = ImageEnhance.Color(pil_image)
    pil_image = enhancer.enhance(saturation)
    
    # Volver a OpenCV
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

def add_texture_noise(image):
    """Agregar ruido de textura (simula papel, scanner, etc.)"""
    h, w, c = image.shape
    
    # Ruido gaussiano sutil
    gaussian_noise = np.random.normal(0, random.uniform(3, 8), (h, w, c))
    
    # Ruido de papel (patr√≥n granular)
    paper_noise = np.random.poisson(random.uniform(0.5, 2.0), (h, w, c))
    
    # Combinar ruidos
    combined_noise = gaussian_noise + paper_noise
    
    # Aplicar al imagen
    noisy = image.astype(np.float32) + combined_noise
    
    return np.clip(noisy, 0, 255).astype(np.uint8)

def add_random_patches(image):
    """Agregar manchas y artefactos aleatorios"""
    h, w = image.shape[:2]
    result = image.copy()
    
    # N√∫mero de patches
    num_patches = random.randint(1, 4)
    
    for _ in range(num_patches):
        # Tama√±o del patch
        patch_size = random.randint(5, 25)
        
        # Posici√≥n aleatoria
        x = random.randint(0, max(1, w - patch_size))
        y = random.randint(0, max(1, h - patch_size))
        
        # Tipo de patch
        patch_type = random.choice(['dark', 'light', 'blur'])
        
        if patch_type == 'dark':
            # Mancha oscura
            intensity = random.uniform(0.3, 0.7)
            result[y:y+patch_size, x:x+patch_size] = \
                result[y:y+patch_size, x:x+patch_size] * intensity
        elif patch_type == 'light':
            # Mancha clara
            addition = random.uniform(20, 60)
            result[y:y+patch_size, x:x+patch_size] = \
                np.clip(result[y:y+patch_size, x:x+patch_size] + addition, 0, 255)
        else:  # blur
            # √Årea borrosa
            patch = result[y:y+patch_size, x:x+patch_size]
            blurred = cv2.GaussianBlur(patch, (5, 5), 2.0)
            result[y:y+patch_size, x:x+patch_size] = blurred
    
    return result

def add_compression_artifacts(image, quality=None):
    """Simular artefactos de compresi√≥n JPEG"""
    if quality is None:
        quality = random.randint(25, 60)
    
    # Convertir a PIL
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Simular compresi√≥n JPEG
    buffer = io.BytesIO()
    pil_image.save(buffer, format='JPEG', quality=quality)
    buffer.seek(0)
    compressed = Image.open(buffer)
    
    # Volver a OpenCV
    return cv2.cvtColor(np.array(compressed), cv2.COLOR_RGB2BGR)

def add_blur_effects(image):
    """Agregar efectos de desenfoque variados"""
    blur_type = random.choice(['gaussian', 'motion', 'defocus'])
    
    if blur_type == 'gaussian':
        # Desenfoque gaussiano
        kernel_size = random.choice([3, 5])
        sigma = random.uniform(0.5, 1.5)
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
        
    elif blur_type == 'motion':
        # Motion blur
        size = random.randint(3, 7)
        angle = random.uniform(0, 180)
        
        # Crear kernel de motion blur
        kernel = np.zeros((size, size))
        kernel[int((size-1)/2), :] = np.ones(size)
        kernel = kernel / size
        
        # Rotar kernel
        center = (size // 2, size // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        kernel = cv2.warpAffine(kernel, rotation_matrix, (size, size))
        
        return cv2.filter2D(image, -1, kernel)
        
    else:  # defocus
        # Defocus blur (desenfoque circular)
        radius = random.randint(2, 4)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (radius*2+1, radius*2+1))
        kernel = kernel.astype(np.float32)
        kernel = kernel / np.sum(kernel)
        
        return cv2.filter2D(image, -1, kernel)

def degrade_document_advanced(image, degradation_params=None):
    """
    Aplicar degradaci√≥n avanzada a documento
    
    Args:
        image: Imagen limpia
        degradation_params: Par√°metros espec√≠ficos de degradaci√≥n
    
    Returns:
        Imagen degradada
    """
    if degradation_params is None:
        degradation_params = {
            'noise_prob': 0.7,
            'blur_prob': 0.6,
            'compression_prob': 0.5,
            'geometric_prob': 0.4,
            'color_prob': 0.8,
            'patches_prob': 0.3
        }
    
    result = image.copy()
    
    # Aplicar degradaciones de forma probabil√≠stica
    
    # 1. Variaciones de color (m√°s com√∫n)
    if random.random() < degradation_params['color_prob']:
        result = add_color_variations(result)
    
    # 2. Ruido de textura
    if random.random() < degradation_params['noise_prob']:
        result = add_texture_noise(result)
    
    # 3. Efectos de desenfoque
    if random.random() < degradation_params['blur_prob']:
        result = add_blur_effects(result)
    
    # 4. Artefactos de compresi√≥n
    if random.random() < degradation_params['compression_prob']:
        result = add_compression_artifacts(result)
    
    # 5. Distorsiones geom√©tricas
    if random.random() < degradation_params['geometric_prob']:
        result = add_geometric_distortions(result)
    
    # 6. Patches y manchas
    if random.random() < degradation_params['patches_prob']:
        result = add_random_patches(result)
    
    return result

def create_massive_training_pairs(target_count=500):
    """
    Crear massive dataset de pares clean/degraded
    
    Args:
        target_count: N√∫mero objetivo de im√°genes degradadas a generar
    """
    print("üî• GENERACI√ìN MASIVA DE DATOS SINT√âTICOS")
    print("üéØ Transfer Learning Gradual Dataset Expansion")
    print("=" * 60)
    
    # Directorios
    clean_dir = "data/train/clean"
    degraded_dir = "data/train/degraded"
    
    # Verificar directorios
    if not os.path.exists(clean_dir):
        print(f"‚ùå No se encontr√≥ directorio clean: {clean_dir}")
        return
    
    os.makedirs(degraded_dir, exist_ok=True)
    
    # Obtener im√°genes limpias base
    clean_files = [f for f in os.listdir(clean_dir) 
                   if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    if len(clean_files) == 0:
        print(f"‚ùå No se encontraron im√°genes limpias en: {clean_dir}")
        return
    
    print(f"üìÅ Im√°genes base encontradas: {len(clean_files)}")
    for f in clean_files:
        print(f"   üì∏ {f}")
    
    # Calcular im√°genes por archivo base
    images_per_base = target_count // len(clean_files)
    remainder = target_count % len(clean_files)
    
    print(f"\nüéØ Objetivo: {target_count} im√°genes degradadas")
    print(f"üìä {images_per_base} im√°genes por archivo base")
    if remainder > 0:
        print(f"üìä +{remainder} im√°genes adicionales en primeros archivos")
    
    # Contador global
    total_generated = 0
    
    # Generar para cada imagen base
    for base_idx, filename in enumerate(clean_files):
        clean_path = os.path.join(clean_dir, filename)
        
        print(f"\nüì∏ Procesando: {filename}")
        
        # Cargar imagen base
        clean_image = cv2.imread(clean_path)
        if clean_image is None:
            print(f"   ‚ùå Error cargando: {filename}")
            continue
        
        print(f"   üìê Dimensiones: {clean_image.shape}")
        
        # Calcular cu√°ntas im√°genes generar para este archivo
        images_to_generate = images_per_base
        if base_idx < remainder:
            images_to_generate += 1
        
        print(f"   üéØ Generando: {images_to_generate} variaciones")
        
        # Generar variaciones
        for i in tqdm(range(images_to_generate), desc=f"   Generando"):
            # Crear nombre √∫nico
            base_name = os.path.splitext(filename)[0]
            degraded_filename = f"{base_name}_synthetic_{i+1:03d}.png"
            degraded_path = os.path.join(degraded_dir, degraded_filename)
            
            # Configurar par√°metros de degradaci√≥n variables
            # M√°s variabilidad seg√∫n el √≠ndice
            intensity = min(1.0, 0.3 + (i / images_to_generate) * 0.7)
            
            degradation_params = {
                'noise_prob': 0.5 + intensity * 0.4,
                'blur_prob': 0.4 + intensity * 0.4,
                'compression_prob': 0.3 + intensity * 0.5,
                'geometric_prob': 0.2 + intensity * 0.3,
                'color_prob': 0.6 + intensity * 0.3,
                'patches_prob': 0.1 + intensity * 0.4
            }
            
            # Aplicar degradaci√≥n
            try:
                degraded_image = degrade_document_advanced(clean_image, degradation_params)
                
                # Guardar imagen degradada
                cv2.imwrite(degraded_path, degraded_image)
                total_generated += 1
                
            except Exception as e:
                print(f"   ‚ùå Error generando {degraded_filename}: {e}")
        
        print(f"   ‚úÖ Completado: {images_to_generate} im√°genes generadas")
    
    # Verificar resultados
    final_degraded_files = [f for f in os.listdir(degraded_dir) 
                           if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    print(f"\nüéâ GENERACI√ìN COMPLETADA")
    print("=" * 60)
    print(f"üìä Total im√°genes degradadas: {len(final_degraded_files)}")
    print(f"üéØ Objetivo cumplido: {total_generated}/{target_count}")
    print(f"üìÅ Ubicaci√≥n: {degraded_dir}")
    
    # Mostrar estad√≠sticas
    print(f"\nüìà ESTAD√çSTICAS DEL DATASET:")
    print(f"   üîπ Im√°genes limpias: {len(clean_files)}")
    print(f"   üîπ Im√°genes degradadas: {len(final_degraded_files)}")
    print(f"   üîπ Factor de expansi√≥n: {len(final_degraded_files) / len(clean_files):.1f}x")
    
    print(f"\nüéØ PR√ìXIMO PASO:")
    print(f"   ‚ñ∂Ô∏è  python training\\gradual_transfer_learning.py")
    print(f"   üìä El dataset expandido mejorar√° significativamente el Transfer Learning")

def verify_dataset():
    """Verificar la integridad del dataset generado"""
    print("\nüîç VERIFICACI√ìN DEL DATASET")
    print("-" * 40)
    
    clean_dir = "data/train/clean"
    degraded_dir = "data/train/degraded"
    
    # Verificar directorios
    for name, path in [("Clean", clean_dir), ("Degraded", degraded_dir)]:
        if os.path.exists(path):
            files = [f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.jpeg'))]
            print(f"üìÅ {name}: {len(files)} archivos")
            
            # Verificar integridad de algunos archivos
            valid_count = 0
            for file in files[:5]:  # Verificar primeros 5
                img_path = os.path.join(path, file)
                img = cv2.imread(img_path)
                if img is not None:
                    valid_count += 1
            
            print(f"   ‚úÖ Archivos verificados: {valid_count}/{min(5, len(files))}")
        else:
            print(f"‚ùå {name}: Directorio no encontrado")

def main():
    """Funci√≥n principal"""
    print("üöÄ GENERADOR DE DATOS SINT√âTICOS")
    print("üéØ Para Transfer Learning Gradual")
    print("=" * 50)
    
    # Generar dataset masivo
    create_massive_training_pairs(target_count=500)
    
    # Verificar integridad
    verify_dataset()
    
    print(f"\n‚ú® ¬°Dataset listo para Transfer Learning Gradual!")

if __name__ == "__main__":
    main()
